{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforcement Learning with BlueSky\n",
    "In this Jupyter Notebook we will look at how to use Bluesky for a simple Reinforcement Learning task. The task at hand will be for the model to predict when to initialize the top of descent while being constraint to the dynamics of the aircraft model.\n",
    "\n",
    "Lets start by importing the relevant modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python-based geo functions\n",
      "Warning: RTree could not be loaded. areafilter get_intersecting and get_knearest won't work\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import bluesky as bs\n",
    "from bluesky.simulation import ScreenIO\n",
    "\n",
    "#The Soft Actor Critic Class used for the Deep Reinforcement Learning part of this notebook\n",
    "from SAC.sac_agent import SAC\n",
    "\n",
    "#Import the functions used during the Reinforcement Learning\n",
    "from functions import reset_env, do_action, get_update, get_reward, get_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dummy class that acts as the screen of BlueSky. Since we don't want to actually load the screen from BlueSky here, a simple and small class is used instead to avoid errors when something within BlueSky is calling the echo function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScreenDummy(ScreenIO):\n",
    "    \"\"\"\n",
    "    Dummy class for the screen. Inherits from ScreenIO to make sure all the\n",
    "    necessary methods are there. This class is there to reimplement the echo\n",
    "    method so that console messages are printed.\n",
    "    \"\"\"\n",
    "    def echo(self, text='', flags=0):\n",
    "        \"\"\"Just print echo messages\"\"\"\n",
    "        print(\"BlueSky console:\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to take is to initialise bluesky (here imported as bs) as a disconnected, single simulation. Next we replace the screen object with our derived variant so that bluesky console messages are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config from C:\\Users\\Jan\\bluesky\\settings.cfg\n",
      "Reading magnetic variation data\n",
      "Loading global navigation database...\n",
      "Reading cache: C:/Users/Jan/bluesky/data/cache\\py3\\navdata.p\n",
      "Failed to load OpenAP performance model\n",
      "Failed to load BADA performance model\n",
      "Successfully loaded plugin AREA\n",
      "Successfully loaded plugin DATAFEED\n"
     ]
    }
   ],
   "source": [
    "# initialize bluesky as non-networked simulation node\n",
    "\n",
    "bs.init(mode='sim', detached=True)\n",
    "\n",
    "# initialize dummy screen\n",
    "bs.scr = ScreenDummy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "\n",
    "To allow reinforcement learning to be incorporated with Bluesky, we need to make some additional functions that create the bridge between the reinforcement learning algorithm and Bluesky. These functions are:\n",
    "\n",
    "* reset_env() -> state_\n",
    "* get_state() -> state_\n",
    "* get_reward(state_) -> reward, done\n",
    "* get_update() -> state_, reward, done\n",
    "* do_action(action) -> None\n",
    "\n",
    "In these functions only 'state_' is used, which refers to the most recent state information. The RL model also takes 'state' as an input for the memory buffer to allow proper learning of the state transition and therefore Critic functions. This 'state' variable refers to the state preceding 'state_'. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reset_env() -> state_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "reset_env() removes the previous aircraft from the simulation. In principle only one aircraft\n",
    "should exist, but loops through all aircraft in this example. Then creates a new aircraft.\n",
    "\"\"\"\n",
    "def reset_env():\n",
    "\n",
    "    for acid in bs.traf.id:\n",
    "        idx = bs.traf.id2idx(acid)\n",
    "        bs.traf.delete(idx)\n",
    "\n",
    "    bs.traf.cre('KL001',actype=\"A320\",acalt=3000,acspd=150)\n",
    "\n",
    "    return get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do_action(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "do_action(action) takes the output of the RL model and translates it to an action intepretable \n",
    "by Blueksy. As the output of the RL model is -1 < action < 1, we first map it to sensible values.\n",
    "Then the action is executed through stack commands in the Bluesky simulator.\n",
    "\"\"\"\n",
    "def do_action(action):\n",
    "    # Transform action to the feet per minute domain\n",
    "    action = action * 2500\n",
    "\n",
    "    # Get aircraft ID of the controlled aircraft\n",
    "    acid = bs.traf.id[0]\n",
    "\n",
    "    # Bluesky interpretes vertical velocity command through altitude commands \n",
    "    # with a vertical speed (magnitude). So check sign of action and give arbitrary \n",
    "    # altitude command\n",
    "    if -250<action<250:\n",
    "        bs.stack.stack(f'ALT {acid},{bs.traf.alt[0]},{250}')\n",
    "    if action > 0:\n",
    "        bs.stack.stack(f'ALT {acid},45000,{action}')\n",
    "    if action < 0:\n",
    "        bs.stack.stack(f'ALT {acid},0,{-action}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_state() -> state_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_state() accesses the traffic arrays of Bluesky to create and return a state for the aircraft.\n",
    "In this case only 1 aircraft is used, so aircraft ID index == 0, but with multiple agents get_state()\n",
    "should require the aircraft ID index as input to access the correct state info.\n",
    "\"\"\"\n",
    "def get_state():\n",
    "    # get current altitude, vertical speed and distance to the runway (set at 200km from origin)\n",
    "    alt = bs.traf.alt[0]\n",
    "    vs = bs.traf.vs[0]\n",
    "    dis =(200 - bs.tools.geo.kwikdist(52,4,bs.traf.lat[0],bs.traf.lon[0])*1.852)\n",
    "\n",
    "    # (roughly) normalize the state values to a mean of zero and variance 1\n",
    "    # (for more complex environments its better to calculate the mean and std over \n",
    "    # a series of interactions with the environment)\n",
    "    alt = (alt - 1500)/3000\n",
    "    vs = vs / 5\n",
    "    dis = (dis - 100)/200\n",
    "\n",
    "    state = [alt,vs,dis]\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_reward(state_) -> reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_reward(state) uses the (new) state variable to calculate a corresponding reward.\n",
    "In principle the designed reward function will control the behaviour of the model after convergence,\n",
    "so reward function design should be done with care. \n",
    "If a model does not do what you want, maybe this function is not stimulating the appropriate behaviour.\n",
    "\"\"\"\n",
    "def get_reward(state):\n",
    "    # denormalize the relevant state variables\n",
    "    alt = (state[0]*3000)+1500\n",
    "    dis = (state[2]*200)+100\n",
    "\n",
    "    # reward part of the function\n",
    "    if dis > 0 and alt> 0:\n",
    "        return abs(3000-alt)*-5/3000, 0\n",
    "    elif alt <= 0:\n",
    "        return -10, 1\n",
    "    elif dis <= 0:\n",
    "        return abs(100-alt)*-20/3000, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_update() -> state_, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_update() returns the values from get_state() and get_reward(state) for the new simulation step in \n",
    "a single function. \n",
    "\"\"\"\n",
    "def get_update():\n",
    "    state_ = get_state()\n",
    "    reward, done = get_reward(state_)\n",
    "    return state_,reward,done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing the Reward Function in a Heatmap\n",
    "To visualize what the behavior of a properly trained model should look like, we visualize the space of the reward function in a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#heatmap of the reward function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the array of all x and y state pairs for which we want to visualize the reward\n",
    "# Note that because the RL model works with normalized state data, we normalize the x and y data\n",
    "xarray = np.flip(np.arange(-10,210,1))\n",
    "yarray = np.flip(np.arange(-50,5000,50))\n",
    "\n",
    "xnorm = (xarray-100)/200\n",
    "ynorm = (yarray-1500)/3000\n",
    "\n",
    "reward_map = np.zeros((len(ynorm),len(xnorm)))\n",
    "\n",
    "for i in range(len(xnorm)):\n",
    "    for j in range(len(ynorm)):\n",
    "        # get reward requires the state as an input, which contains also the vertical speed.\n",
    "        # for now just set that at zero.\n",
    "        state = [ynorm[j],0,xnorm[i]]\n",
    "        reward_map[j,i], _ = get_reward(state) # Returns a scalar reward, and a done flag\n",
    "        \n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=100)\n",
    "figure = ax.imshow(reward_map, extent=[200,-10,-50,5000])\n",
    "\n",
    "cbar = plt.colorbar(figure)\n",
    "cbar.set_label('Reward value')\n",
    "im = ax.get_images()\n",
    "extent =  im[0].get_extent()\n",
    "ax.set_xlabel('Distance till runway (km)')\n",
    "ax.set_ylabel('Altitude (m)')\n",
    "ax.set_aspect(abs((extent[1]-extent[0])/(extent[3]-extent[2]))/2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the image, the reward map gives a penalty for premature landings and for being to high when the distance to runway is equal to zero.\n",
    "furthermore, the lowest penalty is given for flying a level flight at 3000m altitude for as long as possible.\n",
    "\n",
    "The expected behavior of a properly trained model is therefore to see it staying at 3000m for as long as possible before steeply descending to minimize the penalty at D = 0. \n",
    "\n",
    "#### Training the model:\n",
    "\n",
    "The next step is to train the model within bluesky, subjected to this reward function. \n",
    "\n",
    "To speed up the training the simulation timestep is set to 1 second and fastforward is activated through the stack command \"bs.stack.stack('DT 1; FF)\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE USED <torch.cuda.device object at 0x00000284F620D1B0> Quadro P2000\n",
      "BlueSky console: Base dt set to 1.0\n",
      "performance dt is unchanged.\n",
      "asas dt is unchanged.\n",
      "AREA dt is unchanged.\n",
      "DATAFEED.update dt set to 1.0 to match integer multiple of base dt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jan\\Anaconda3\\envs\\BSRLnotebook\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Jan\\Anaconda3\\envs\\BSRLnotebook\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "-177.2199084945\n",
      "-126.77108623108336\n",
      "-110.7987651052778\n",
      "-95.10422728316667\n",
      "-83.258329048\n",
      "-74.72666273419443\n",
      "-68.11839767661907\n",
      "-63.011062022270835\n",
      "-59.125399426092606\n",
      "-55.91806374238334\n",
      "-53.322223103090906\n",
      "-51.04310477761111\n",
      "-49.216469511\n",
      "-47.60028493141667\n",
      "-46.1259693647\n",
      "-44.779797377260415\n",
      "-43.52071743665687\n",
      "-42.45333175998149\n",
      "-41.463474974421054\n",
      "-40.53661219172499\n",
      "-39.70053748822222\n",
      "-38.91006605618182\n",
      "-38.18597110750724\n",
      "-37.5120322846875\n",
      "-36.865173974473336\n",
      "-36.26627103937179\n",
      "-35.71038264574074\n",
      "-35.1507899994881\n",
      "-34.63642735579885\n",
      "-34.15290202562778\n",
      "-33.67677743398388\n",
      "-33.23207621580729\n",
      "-32.80086925859091\n",
      "-32.39040216070098\n",
      "-31.987339439833335\n",
      "-31.613907090847224\n",
      "-31.251787147842343\n",
      "-30.911328726267545\n",
      "-30.58170379208974\n",
      "-30.266021690141667\n",
      "-29.967826721105684\n",
      "-29.68536783315476\n",
      "-29.405802824724802\n",
      "-29.143551260799242\n",
      "-28.896115284259256\n",
      "-28.662568592507245\n",
      "-28.436091177390068\n",
      "-28.223307920378474\n",
      "-28.024761355013602\n",
      "-27.824238959996666\n",
      "-27.636099402166668\n",
      "-27.44437847996474\n",
      "-27.25813632424528\n",
      "-27.076932002354933\n",
      "-26.898828373939395\n",
      "-26.72859714074405\n",
      "-26.55879167657602\n",
      "-26.395874345000003\n",
      "-26.232553901350283\n",
      "-26.079268762658334\n",
      "-25.930963371642076\n",
      "-25.786522946325267\n",
      "-25.649438409798943\n",
      "-25.520962790596354\n",
      "-25.39286426542308\n",
      "-25.262692262881313\n",
      "-25.142477105629354\n",
      "-25.02431723442647\n",
      "-24.91024858705314\n",
      "-24.796327012678574\n",
      "-24.684374731917845\n",
      "-24.578343435395837\n",
      "-24.47039621674658\n",
      "-24.36957757011712\n",
      "-24.272614110977777\n",
      "-24.1714521922193\n",
      "-24.07437812972078\n",
      "-23.983219868382477\n",
      "-23.890833043116032\n",
      "-23.804346057029164\n",
      "-23.720110420958846\n",
      "-23.635183442038617\n",
      "-23.554130158311246\n",
      "-23.47684047081151\n",
      "-23.402196367515682\n",
      "-23.323016428653098\n",
      "-23.25002980598276\n",
      "-23.175852616066287\n",
      "-23.104911894589886\n",
      "-23.03414862952222\n",
      "-22.968964806567765\n",
      "-22.900695685088767\n",
      "-22.83426084052688\n",
      "-22.77159794322163\n",
      "-22.71062243659649\n",
      "-22.649215274361108\n",
      "-22.587961300506876\n",
      "-22.530937781267006\n",
      "-22.470004754333335\n"
     ]
    }
   ],
   "source": [
    "bs.stack.stack('DT 1;FF')\n",
    "\n",
    "N_episodes = 1000 # how many episodes should the model train\n",
    "Rewards = np.zeros(N_episodes)\n",
    "\n",
    "action_frequency = 30 # how often should the RL model select an action for the aircraft (default once every 30 seconds)\n",
    "\n",
    "action_dim = 1\n",
    "state_dim = 3\n",
    "agent = SAC(action_dim,state_dim)\n",
    "\n",
    "alt = [[]]*N_episodes\n",
    "dist = [[]]*N_episodes\n",
    "\n",
    "for episode in range(N_episodes):\n",
    "    #initialise episode\n",
    "    done = 0\n",
    "    state = reset_env()\n",
    "    total_reward = 0\n",
    "\n",
    "    temp_alt = np.array([])\n",
    "    temp_dist = np.array([])\n",
    "    while not done:\n",
    "\n",
    "        action = agent.step(state)\n",
    "        do_action(action[0][0])\n",
    "\n",
    "        # Progress the simulation \n",
    "        for i in range(action_frequency):\n",
    "            bs.sim.step()\n",
    "        \n",
    "        # Get the information regarding the new environment state\n",
    "        state_, reward, done = get_update(state)\n",
    "\n",
    "        # Store the state transition and preform a training update\n",
    "        agent.store_transition(state,state_,reward,action[0][0],done)\n",
    "        agent.train()\n",
    "\n",
    "        # set the old state to the new state\n",
    "        state = state_\n",
    "\n",
    "        # Save relevant information for plotting purposes\n",
    "        total_reward += reward\n",
    "        temp_alt = np.append(temp_alt,(state[0]*3000)+1500)\n",
    "        temp_dist = np.append(temp_dist,(state[2]*200)+100)\n",
    "\n",
    "    alt[episode] = temp_alt\n",
    "    dist[episode] = temp_dist\n",
    "    Rewards[episode] = total_reward\n",
    "\n",
    "    # Some printing to see if the reward is increasing, e.g. is the model learning\n",
    "    if episode % 100 == 0:\n",
    "        print(np.mean(Rewards[0:episode]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting after Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "did_training = False\n",
    "\n",
    "if did_training:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(dist[9],alt[9], label='initial (random) behaviour')\n",
    "    ax.plot(dist[99],alt[99], label='policy after 100 episodes')\n",
    "    ax.plot(dist[999],alt[999], label='policy after 1000 episodes')\n",
    "    ax.legend()\n",
    "    ax.invert_xaxis()\n",
    "    plt.show()\n",
    "else:\n",
    "    fig = Image.open('figures/TrajectoryEvolution.png')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "did_training = False\n",
    "\n",
    "if did_training:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(Rewards)\n",
    "    ax.set_xlabel('Episode Number')\n",
    "    ax.set_ylabel('Obtained Reward')\n",
    "    plt.show()\n",
    "else:\n",
    "    fig = Image.open('figures/RewardEvolution.png')\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42674b6842dc90fcec5a9ff48dfdca6628f105653c579a4061de22a336234134"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('BSRLnotebook')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
